Ex2.1  
The cumlative rewards are shown in the figure 3 generated by the Ex2.1.py. But I could not understand what the cumlative probability means. Cumlative probability should have some kind of probability distribution. I think the optimal action has included the best action before the step and calculate the probability then, which is not the probability distribution.

Ex2.2
The former rewards, the less weights. Too obvious to be true.

Ex2.3
The action value would go random walk every 20 steps. The result is shown in figure Ex2.3.pdf. I omit the first 10 steps since it will always choose the first action which is best at the first step.

Ex2.4
Because the exploration in the early steps will lead to the decrease in the action-value estimate. When the learner try all the actions once, it is likely that the estimate of the best action decrese least since the best action probably give the highest rewards. After selecting the best action according to the greedy method, its action-value estimate decrease and probably is smaller than other actions. Then the learner miss the best action. Thus, the performance oscillates.
